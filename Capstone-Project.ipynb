{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Refugees in the Age of Gloabl Warming\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "This project focuses on monitoring refugee and population information around the world based on temperature changes over time.\n",
    "\n",
    "The project follows the following steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Installs\n",
    "# pip3 install -U country_converter \n",
    "# pip3 install -U pandasql \n",
    "# pip3 install -U us\n",
    "\n",
    "# Imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "import boto3\n",
    "import psycopg2\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "from sqlalchemy.engine import create_engine\n",
    "# Source: https://github.com/konstantinstadler/country_converter\n",
    "import country_converter as coco\n",
    "from pandasql import sqldf\n",
    "# Source: https://github.com/unitedstates/python-us\n",
    "import us\n",
    "# Source: https://stackoverflow.com/questions/23668427/pandas-three-way-joining-multiple-dataframes-on-columns\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "The plan is to build a data warehouse for analytical processes, so analysts can design recurring and ad hoc reports over time using SQL. There is a strong emphasis in ensuring the warehouse is easy to interpret, performant, and quality assured.\n",
    " \n",
    "#### Data Sources and Content\n",
    "\n",
    "There are four source datasets:\n",
    " 1. City_temperature.csv\n",
    "     - Summary: average daily temperature for all major cities in the world from 1995 - 2020\n",
    "     - Source: University of Dayton - separate txt files available for each city [here](https://academic.udayton.edu/kissock/http/Weather/default.htm). The data is available for research and non-commercial purposes only. Refer to [this page](https://academic.udayton.edu/kissock/http/Weather/default.htm) for license.\n",
    "     - Secondary source: SRK via Kaggle - [link](https://www.kaggle.com/sudalairajkumar/daily-temperature-of-major-cities)\n",
    " 2. Country_population_total_long.csv\n",
    "     - Summary: annual population counts by country from 1960 - 2017\n",
    "     - Source: The World Bank - [link](https://data.worldbank.org/indicator/SP.POP.TOTL)\n",
    "     - Secondary source: Devakumar kp via Kaggle - [link](https://www.kaggle.com/imdevskp/world-population-19602018?select=population_total_long.csv)\n",
    " 3. UNdata_City_Population_20210315.csv\n",
    "     - Summary: annual population counts by city from 1970 - 2020 (contains gaps in 1970's)\n",
    "     - Source: UN Data - [link](https://data.un.org/Data.aspx?d=POP&f=tableCode%3A240)\n",
    " 4. UNdata_Refugees_20210217.csv\n",
    "     - Summary: annual refugee counts from 1975 - 2016 by country of residence and country of origin\n",
    "     - Source: UN Data - [link](http://data.un.org/Data.aspx?d=UNHCR&f=indID%3aType-Ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Read in Each Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Year</th>\n",
       "      <th>AvgTemperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Algiers</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1995</td>\n",
       "      <td>64.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Algiers</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1995</td>\n",
       "      <td>49.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Algiers</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1995</td>\n",
       "      <td>48.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Algiers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1995</td>\n",
       "      <td>46.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Algiers</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1995</td>\n",
       "      <td>47.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Region  Country State     City  Month  Day  Year  AvgTemperature\n",
       "0  Africa  Algeria   NaN  Algiers      1    1  1995            64.2\n",
       "1  Africa  Algeria   NaN  Algiers      1    2  1995            49.4\n",
       "2  Africa  Algeria   NaN  Algiers      1    3  1995            48.8\n",
       "3  Africa  Algeria   NaN  Algiers      1    4  1995            46.4\n",
       "4  Africa  Algeria   NaN  Algiers      1    5  1995            47.9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = pd.read_csv('Data/temperature_data/city_temperature.csv', engine = 'python')\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Population Counts by Country and Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>1960</td>\n",
       "      <td>54211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1960</td>\n",
       "      <td>8996973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angola</td>\n",
       "      <td>1960</td>\n",
       "      <td>5454933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1960</td>\n",
       "      <td>1608800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>1960</td>\n",
       "      <td>13411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country Name  Year    Count\n",
       "0        Aruba  1960    54211\n",
       "1  Afghanistan  1960  8996973\n",
       "2       Angola  1960  5454933\n",
       "3      Albania  1960  1608800\n",
       "4      Andorra  1960    13411"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_pop_df = pd.read_csv('Data/country_population_data/country_population_total_long.csv', engine = 'python')\n",
    "country_pop_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Population Counts by City and Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country or Area</th>\n",
       "      <th>Year</th>\n",
       "      <th>Area</th>\n",
       "      <th>Sex</th>\n",
       "      <th>City</th>\n",
       "      <th>City type</th>\n",
       "      <th>Record Type</th>\n",
       "      <th>Reliability</th>\n",
       "      <th>Source Year</th>\n",
       "      <th>Value</th>\n",
       "      <th>Value Footnotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>2019</td>\n",
       "      <td>Total</td>\n",
       "      <td>Both Sexes</td>\n",
       "      <td>MARIEHAMN</td>\n",
       "      <td>City proper</td>\n",
       "      <td>Estimate - de jure</td>\n",
       "      <td>Final figure, complete</td>\n",
       "      <td>2020</td>\n",
       "      <td>11711.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>2019</td>\n",
       "      <td>Total</td>\n",
       "      <td>Male</td>\n",
       "      <td>MARIEHAMN</td>\n",
       "      <td>City proper</td>\n",
       "      <td>Estimate - de jure</td>\n",
       "      <td>Final figure, complete</td>\n",
       "      <td>2020</td>\n",
       "      <td>5606.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>2019</td>\n",
       "      <td>Total</td>\n",
       "      <td>Female</td>\n",
       "      <td>MARIEHAMN</td>\n",
       "      <td>City proper</td>\n",
       "      <td>Estimate - de jure</td>\n",
       "      <td>Final figure, complete</td>\n",
       "      <td>2020</td>\n",
       "      <td>6105.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>Total</td>\n",
       "      <td>Both Sexes</td>\n",
       "      <td>MARIEHAMN</td>\n",
       "      <td>City proper</td>\n",
       "      <td>Estimate - de jure</td>\n",
       "      <td>Final figure, complete</td>\n",
       "      <td>2019</td>\n",
       "      <td>11709.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>Total</td>\n",
       "      <td>Male</td>\n",
       "      <td>MARIEHAMN</td>\n",
       "      <td>City proper</td>\n",
       "      <td>Estimate - de jure</td>\n",
       "      <td>Final figure, complete</td>\n",
       "      <td>2019</td>\n",
       "      <td>5620.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country or Area  Year   Area         Sex       City    City type  \\\n",
       "0   Åland Islands  2019  Total  Both Sexes  MARIEHAMN  City proper   \n",
       "1   Åland Islands  2019  Total        Male  MARIEHAMN  City proper   \n",
       "2   Åland Islands  2019  Total      Female  MARIEHAMN  City proper   \n",
       "3   Åland Islands  2018  Total  Both Sexes  MARIEHAMN  City proper   \n",
       "4   Åland Islands  2018  Total        Male  MARIEHAMN  City proper   \n",
       "\n",
       "          Record Type             Reliability  Source Year    Value  \\\n",
       "0  Estimate - de jure  Final figure, complete         2020  11711.0   \n",
       "1  Estimate - de jure  Final figure, complete         2020   5606.0   \n",
       "2  Estimate - de jure  Final figure, complete         2020   6105.0   \n",
       "3  Estimate - de jure  Final figure, complete         2019  11709.0   \n",
       "4  Estimate - de jure  Final figure, complete         2019   5620.5   \n",
       "\n",
       "  Value Footnotes  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  \n",
       "3               1  \n",
       "4               1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_pop_df = pd.read_csv('Data/city_population_data/UNdata_City_Population_20210315.csv', engine = 'python')\n",
    "city_pop_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Refugee Counts by Year, Country of Residence, and Country of Origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country or territory of asylum or residence</th>\n",
       "      <th>Country or territory of origin</th>\n",
       "      <th>Year</th>\n",
       "      <th>Refugees</th>\n",
       "      <th>Refugees assisted by UNHCR</th>\n",
       "      <th>Total refugees and people in refugee-like situations</th>\n",
       "      <th>Total refugees and people in refugee-like situations assisted by UNHCR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>2016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Islamic Rep. of Iran</td>\n",
       "      <td>2016</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>2016</td>\n",
       "      <td>59737.0</td>\n",
       "      <td>59737.0</td>\n",
       "      <td>59737.0</td>\n",
       "      <td>59737.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>China</td>\n",
       "      <td>2016</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albania</td>\n",
       "      <td>Dem. Rep. of the Congo</td>\n",
       "      <td>2016</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country or territory of asylum or residence Country or territory of origin  \\\n",
       "0                                 Afghanistan                           Iraq   \n",
       "1                                 Afghanistan           Islamic Rep. of Iran   \n",
       "2                                 Afghanistan                       Pakistan   \n",
       "3                                     Albania                          China   \n",
       "4                                     Albania         Dem. Rep. of the Congo   \n",
       "\n",
       "   Year  Refugees  Refugees assisted by UNHCR  \\\n",
       "0  2016       1.0                         1.0   \n",
       "1  2016      33.0                        33.0   \n",
       "2  2016   59737.0                     59737.0   \n",
       "3  2016      11.0                        11.0   \n",
       "4  2016       3.0                         3.0   \n",
       "\n",
       "   Total refugees and people in refugee-like situations  \\\n",
       "0                                                1.0      \n",
       "1                                               33.0      \n",
       "2                                            59737.0      \n",
       "3                                               11.0      \n",
       "4                                                3.0      \n",
       "\n",
       "   Total refugees and people in refugee-like situations assisted by UNHCR  \n",
       "0                                                1.0                       \n",
       "1                                               33.0                       \n",
       "2                                            59737.0                       \n",
       "3                                               11.0                       \n",
       "4                                                3.0                       "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refugee_df = pd.read_csv('Data/refugee_data/UNdata_Refugees_20210317.csv', engine = 'python')\n",
    "refugee_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore, Assess, and Clean the Data\n",
    "\n",
    "#### Cleaning Steps Based on Exploring the Data in the Proceeding Step\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Cleaning steps based on exploring the data in the proceeding step\n",
    "\n",
    "# Temperature data\n",
    "\n",
    "# There are records with a day value of 0 and year values of 200 and 201, \n",
    "# and missing termperatuers are represented as -99. Exclude all of them.\n",
    "temp_df = temp_df[(temp_df.Day > 0) & (temp_df.Year >= 1995) & (temp_df.AvgTemperature != -99)]\n",
    "\n",
    "# Add a date field\n",
    "temp_df['Date'] = pd.to_datetime(temp_df[[\"Year\", \"Month\", \"Day\"]]).dt.date\n",
    "\n",
    "# Add a date key\n",
    "temp_df['DateKey'] = temp_df.Date.apply(lambda x: x.strftime('%Y%m%d'))\n",
    "\n",
    "# Correct spelling\n",
    "temp_df.Country[temp_df.Country == 'Equador'] = 'Ecuador'\n",
    "\n",
    "# Create a state field that contains no null values so it can be grouped on\n",
    "temp_df['StateNoNull'] = temp_df['State'].mask(pd.isnull, 'State')\n",
    "\n",
    "# There are records with duplicate content, but two different temperatures listed.\n",
    "# Replace exisitng average temperature field with max to resolve duplication.\n",
    "# Source: https://laptrinhx.com/sql-like-window-functions-in-pandas-1608955182/\n",
    "temp_df['AvgTemperature'] = temp_df.groupby(['Country', 'StateNoNull', 'City', 'Date'])['AvgTemperature']\\\n",
    "                        .transform('max')\n",
    "\n",
    "# Drop state field that contains no null values\n",
    "temp_df = temp_df.drop(columns=['StateNoNull'])\n",
    "\n",
    "# Drop duplicates\n",
    "temp_df = temp_df.drop_duplicates()\n",
    "\n",
    "# Population Counts by Country and Year\n",
    "\n",
    "# Rename columns to be more descriptive\n",
    "country_pop_df.columns = ['Country', 'Year', 'Country_Population']\n",
    "\n",
    "country_pop_df = country_pop_df.drop_duplicates()\n",
    "\n",
    "# Population Counts by City and Year\n",
    "\n",
    "# Filter on sex to only include both sexes since other sources don't include this breakdown.\n",
    "# Note I verfied there are 4,751 distinct cities and all cities have a both sexes row\n",
    "city_pop_df[['City']].nunique()\n",
    "city_pop_df[['Sex','City']].groupby(['Sex']).nunique()\n",
    "city_pop_df = city_pop_df[city_pop_df.Sex == 'Both Sexes']\n",
    "\n",
    "# By filtering the sex breakdown to one value, the field can be dropped\n",
    "city_pop_df = city_pop_df.drop(columns=['Sex'])\n",
    "\n",
    "# Check how many inputs are in the Area column\n",
    "city_pop_df[['Area']].drop_duplicates()\n",
    "\n",
    "# Remove Area coulmn with there being only one input\n",
    "city_pop_df = city_pop_df.drop(columns=['Area'])\n",
    "\n",
    "# Change population format to integer\n",
    "city_pop_df['Value'] = city_pop_df['Value'].apply(np.int64)\n",
    "\n",
    "# Rename columns for naming consistencies\n",
    "city_pop_df.columns = ['Country',\n",
    "                       'Year',\n",
    "                       'City',\n",
    "                       'City_Type',\n",
    "                       'Record_Type',\n",
    "                       'Reliability',\n",
    "                       'Source_Year',\n",
    "                       'City_Population',\n",
    "                       'Population_Notes']\n",
    "\n",
    "# Drop duplicates\n",
    "city_pop_df = city_pop_df.drop_duplicates()\n",
    "\n",
    "# Refugee Counts by Year, Country of Residence, and Country of Origin\n",
    "\n",
    "# Rename columns for naming consistencies\n",
    "refugee_df.columns = ['Asylum_Country',\n",
    "                      'Origin_Country',\n",
    "                      'Year',\n",
    "                      'Refugees',\n",
    "                      'Refugees_Assisted_by_UNHCR',\n",
    "                      'Refugee_Like_Population',\n",
    "                      'Refugee_Like_Population_Assisted_by_UNHCR']\n",
    "\n",
    "# Simplify name\n",
    "refugee_df.Asylum_Country[refugee_df.Asylum_Country == 'Serbia (and Kosovo: S/RES/1244 (1999))'] = 'Serbia'\n",
    "refugee_df.Origin_Country[refugee_df.Origin_Country == 'Serbia (and Kosovo: S/RES/1244 (1999))'] = 'Serbia'\n",
    "\n",
    "# Drop duplicates\n",
    "refugee_df = refugee_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Asylum_Country</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>nunique</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Asylum_Country\n",
       "            nunique\n",
       "Year               \n",
       "1975             50\n",
       "1976             53\n",
       "1977             72\n",
       "1978             82\n",
       "1979             88\n",
       "1980             90\n",
       "1981             92\n",
       "1982             94\n",
       "1983             97\n",
       "1984             96\n",
       "1985             99\n",
       "1986             97\n",
       "1987             98\n",
       "1988             98\n",
       "1989            101\n",
       "1990            112\n",
       "1991            118\n",
       "1992            132\n",
       "1993            139\n",
       "1994            142\n",
       "1995            143\n",
       "1996            143\n",
       "1997            147\n",
       "1998            146\n",
       "1999            151\n",
       "2000            150\n",
       "2001            151\n",
       "2002            147\n",
       "2003            147\n",
       "2004            148\n",
       "2005            149\n",
       "2006            153\n",
       "2007            155\n",
       "2008            156\n",
       "2009            161\n",
       "2010            163\n",
       "2011            169\n",
       "2012            167\n",
       "2013            169\n",
       "2014            170\n",
       "2015            172\n",
       "2016            173"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summary_stats(df, GroupByList, SelectList, AggList = ['min', 'max', 'nunique']):\n",
    "    \"\"\"\n",
    "    Returns summary level information\n",
    "    \n",
    "    Inputs:\n",
    "    df - dataframe\n",
    "    GroupByList - columns to summarize on\n",
    "    SelectList - columns to return\n",
    "    AggList - how to summarize the results\n",
    "    \"\"\"\n",
    "    return df.groupby(GroupByList)[SelectList].agg(AggList).head(50)\n",
    "\n",
    "# Temperature data\n",
    "\n",
    "# Note that there are seven regions\n",
    "summary_stats(df = temp_df,\n",
    "              GroupByList = ['Region'],\n",
    "              SelectList = ['Date', 'AvgTemperature'])\n",
    "\n",
    "# Very consistent going back to 1995\n",
    "summary_stats(df = temp_df,\n",
    "              GroupByList = ['Year'],\n",
    "              SelectList = ['City'],\n",
    "              AggList = ['nunique'])\n",
    "\n",
    "# Country populations over time data\n",
    "\n",
    "summary_stats(df = country_pop_df,\n",
    "              GroupByList = ['Country'],\n",
    "              SelectList = ['Year', 'Country_Population'])\n",
    "\n",
    "# Very consistent going back to 1960\n",
    "summary_stats(df = country_pop_df,\n",
    "              GroupByList = ['Year'],\n",
    "              SelectList = ['Country'],\n",
    "              AggList = ['nunique'])\n",
    "\n",
    "# City populations over time data\n",
    "\n",
    "# There are gaps in time.\n",
    "summary_stats(df = city_pop_df,\n",
    "              GroupByList = ['Country'],\n",
    "              SelectList = ['Year', 'City_Population'])\n",
    "\n",
    "# By year 2000, data collection is much more complete accross cities\n",
    "summary_stats(df = city_pop_df,\n",
    "              GroupByList = ['Year'],\n",
    "              SelectList = ['City'],\n",
    "              AggList = ['nunique'])\n",
    "\n",
    "# Refugee Counts by Year, Country of Residence, and Country of Origin\n",
    "\n",
    "# Takeaways from the following three comparisons:\n",
    "# UNHCR related counts are populated substantially less\n",
    "# Refugees vs. refugee-like: they differ slightly\n",
    "summary_stats(df = refugee_df,\n",
    "              GroupByList = ['Asylum_Country'],\n",
    "              SelectList = ['Refugees', 'Refugees_Assisted_by_UNHCR'])\n",
    "\n",
    "\n",
    "summary_stats(df = refugee_df,\n",
    "              GroupByList = ['Asylum_Country'],\n",
    "              SelectList = ['Refugee_Like_Population', 'Refugee_Like_Population_Assisted_by_UNHCR'])\n",
    "\n",
    "\n",
    "summary_stats(df = refugee_df,\n",
    "              GroupByList = ['Asylum_Country'],\n",
    "              SelectList = ['Refugee_Like_Population', 'Refugees'])\n",
    "\n",
    "# There are gaps in time.\n",
    "summary_stats(df = refugee_df,\n",
    "              GroupByList = ['Asylum_Country'],\n",
    "              SelectList = ['Year'])\n",
    "\n",
    "# Seems consistent by year, especially considering new countries forming over time\n",
    "summary_stats(df = refugee_df,\n",
    "              GroupByList = ['Year'],\n",
    "              SelectList = ['Asylum_Country'],\n",
    "              AggList = ['nunique'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Asylum_Country</th>\n",
       "      <th>Origin_Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Refugees</th>\n",
       "      <th>Refugees_Assisted_by_UNHCR</th>\n",
       "      <th>Refugee_Like_Population</th>\n",
       "      <th>Refugee_Like_Population_Assisted_by_UNHCR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Asylum_Country, Origin_Country, Year, Refugees, Refugees_Assisted_by_UNHCR, Refugee_Like_Population, Refugee_Like_Population_Assisted_by_UNHCR]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def duplicate_check(df, DuplicateList, SortList):\n",
    "    \"\"\"\n",
    "    Returns how consistent information is populated over time\n",
    "    \n",
    "    Inputs:\n",
    "    df - dataframe\n",
    "    DuplicateList - columns to check for duplicates\n",
    "    SortList - columns to sort by\n",
    "    \"\"\"\n",
    "    return df[df.duplicated(DuplicateList, keep=False)].sort_values(by = SortList)\n",
    "\n",
    "# Originally 94 duplicates, but after fix the above, no duplicates remain\n",
    "duplicate_check(df = temp_df,\n",
    "                DuplicateList = ['State', 'City', 'Date'],\n",
    "                SortList = ['City', 'Date'])\n",
    "\n",
    "# No duplicates\n",
    "duplicate_check(df = country_pop_df,\n",
    "                DuplicateList = ['Country', 'Year'],\n",
    "                SortList = ['Country', 'Year'])\n",
    "\n",
    "# No duplicates\n",
    "duplicate_check(df = city_pop_df,\n",
    "                DuplicateList = ['City', 'Year', 'City_Type', 'Record_Type',\n",
    "                                 'Reliability', 'Source_Year', 'Population_Notes'],\n",
    "                SortList = ['City', 'Year'])\n",
    "\n",
    "# No duplicates\n",
    "duplicate_check(df = refugee_df,\n",
    "                DuplicateList = ['Asylum_Country', 'Origin_Country', 'Year'],\n",
    "                SortList = ['Asylum_Country', 'Origin_Country', 'Year'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Date</th>\n",
       "      <th colspan=\"3\" halign=\"left\">AvgTemperature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>nunique</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>nunique</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>9231</td>\n",
       "      <td>35.3</td>\n",
       "      <td>90.9</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bahamas</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>9161</td>\n",
       "      <td>58.7</td>\n",
       "      <td>91.8</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barbados</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>2018-05-20</td>\n",
       "      <td>8349</td>\n",
       "      <td>74.2</td>\n",
       "      <td>88.0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Belize</th>\n",
       "      <td>1995-01-03</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>8867</td>\n",
       "      <td>64.6</td>\n",
       "      <td>92.9</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bermuda</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>2010-08-22</td>\n",
       "      <td>5558</td>\n",
       "      <td>51.1</td>\n",
       "      <td>85.4</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bolivia</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>9225</td>\n",
       "      <td>32.8</td>\n",
       "      <td>63.4</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brazil</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>9208</td>\n",
       "      <td>44.8</td>\n",
       "      <td>93.4</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colombia</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>9196</td>\n",
       "      <td>46.7</td>\n",
       "      <td>66.7</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Costa Rica</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>9130</td>\n",
       "      <td>63.1</td>\n",
       "      <td>85.6</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cuba</th>\n",
       "      <td>1995-01-02</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>9094</td>\n",
       "      <td>46.9</td>\n",
       "      <td>88.3</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dominican Republic</th>\n",
       "      <td>1995-01-10</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>8513</td>\n",
       "      <td>65.0</td>\n",
       "      <td>87.4</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ecuador</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>9065</td>\n",
       "      <td>49.1</td>\n",
       "      <td>90.0</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guatemala</th>\n",
       "      <td>1995-01-05</td>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>8710</td>\n",
       "      <td>51.2</td>\n",
       "      <td>79.8</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guyana</th>\n",
       "      <td>1996-04-30</td>\n",
       "      <td>2011-11-12</td>\n",
       "      <td>2136</td>\n",
       "      <td>67.0</td>\n",
       "      <td>90.6</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Haiti</th>\n",
       "      <td>1995-01-02</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>5816</td>\n",
       "      <td>71.4</td>\n",
       "      <td>97.4</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Honduras</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>9095</td>\n",
       "      <td>56.1</td>\n",
       "      <td>88.0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nicaragua</th>\n",
       "      <td>1995-07-01</td>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>8737</td>\n",
       "      <td>68.5</td>\n",
       "      <td>93.9</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Panama</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>9192</td>\n",
       "      <td>73.4</td>\n",
       "      <td>90.6</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peru</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>2015-11-18</td>\n",
       "      <td>7606</td>\n",
       "      <td>57.5</td>\n",
       "      <td>81.8</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Suriname</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>7599</td>\n",
       "      <td>71.6</td>\n",
       "      <td>90.5</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uruguay</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>9229</td>\n",
       "      <td>35.7</td>\n",
       "      <td>87.4</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Venezuela</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>9121</td>\n",
       "      <td>71.5</td>\n",
       "      <td>89.9</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Date                     AvgTemperature        \\\n",
       "                           min         max nunique            min   max   \n",
       "Country                                                                   \n",
       "Argentina           1995-01-01  2020-05-13    9231           35.3  90.9   \n",
       "Bahamas             1995-01-01  2020-05-12    9161           58.7  91.8   \n",
       "Barbados            1995-01-01  2018-05-20    8349           74.2  88.0   \n",
       "Belize              1995-01-03  2020-05-12    8867           64.6  92.9   \n",
       "Bermuda             1995-01-01  2010-08-22    5558           51.1  85.4   \n",
       "Bolivia             1995-01-01  2020-05-13    9225           32.8  63.4   \n",
       "Brazil              1995-01-01  2020-05-13    9208           44.8  93.4   \n",
       "Colombia            1995-01-01  2020-05-13    9196           46.7  66.7   \n",
       "Costa Rica          1995-01-01  2020-05-13    9130           63.1  85.6   \n",
       "Cuba                1995-01-02  2020-05-12    9094           46.9  88.3   \n",
       "Dominican Republic  1995-01-10  2020-05-12    8513           65.0  87.4   \n",
       "Ecuador             1995-01-01  2020-05-13    9065           49.1  90.0   \n",
       "Guatemala           1995-01-05  2020-05-13    8710           51.2  79.8   \n",
       "Guyana              1996-04-30  2011-11-12    2136           67.0  90.6   \n",
       "Haiti               1995-01-02  2020-05-12    5816           71.4  97.4   \n",
       "Honduras            1995-01-01  2020-05-12    9095           56.1  88.0   \n",
       "Nicaragua           1995-07-01  2020-04-22    8737           68.5  93.9   \n",
       "Panama              1995-01-01  2020-05-13    9192           73.4  90.6   \n",
       "Peru                1995-01-01  2015-11-18    7606           57.5  81.8   \n",
       "Suriname            1995-01-01  2020-05-13    7599           71.6  90.5   \n",
       "Uruguay             1995-01-01  2020-05-13    9229           35.7  87.4   \n",
       "Venezuela           1995-01-01  2020-05-12    9121           71.5  89.9   \n",
       "\n",
       "                            \n",
       "                   nunique  \n",
       "Country                     \n",
       "Argentina              507  \n",
       "Bahamas                293  \n",
       "Barbados               120  \n",
       "Belize                 233  \n",
       "Bermuda                307  \n",
       "Bolivia                211  \n",
       "Brazil                 407  \n",
       "Colombia               154  \n",
       "Costa Rica             160  \n",
       "Cuba                   301  \n",
       "Dominican Republic     170  \n",
       "Ecuador                350  \n",
       "Guatemala              220  \n",
       "Guyana                 135  \n",
       "Haiti                  200  \n",
       "Honduras               270  \n",
       "Nicaragua              180  \n",
       "Panama                 144  \n",
       "Peru                   235  \n",
       "Suriname               151  \n",
       "Uruguay                449  \n",
       "Venezuela              162  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summary_stats_in_region(GroupBy, Region):\n",
    "    \"\"\"\n",
    "    Returns summary information within a specified region\n",
    "    \n",
    "    Inputs:\n",
    "    GroupBy - column to summarizer on\n",
    "    Region - region to filter on\n",
    "    \n",
    "    Input Options:\n",
    "    GroupBy: City, Country, State\n",
    "    Region: Africa, Asia, Australia/South Pacific,\n",
    "            Europe, Middle East, North America,\n",
    "            South/Central America & Carribean\n",
    "    \"\"\"\n",
    "    return temp_df[[GroupBy, 'Date', 'AvgTemperature']].where(temp_df.Region == Region) \\\n",
    "               .groupby([GroupBy]) \\\n",
    "               .agg(['min', 'max', 'nunique'])\n",
    "\n",
    "# Note: there are some time gaps in cities.\n",
    "summary_stats_in_region(GroupBy = 'Country', Region = 'South/Central America & Carribean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Asylum_Country</th>\n",
       "      <th>Origin_Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Refugees</th>\n",
       "      <th>Refugees_Assisted_by_UNHCR</th>\n",
       "      <th>Refugee_Like_Population</th>\n",
       "      <th>Refugee_Like_Population_Assisted_by_UNHCR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>Israel</td>\n",
       "      <td>Dem. Rep. of the Congo</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>208.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2941</th>\n",
       "      <td>Malaysia</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2953</th>\n",
       "      <td>Malaysia</td>\n",
       "      <td>Rep. of Moldova</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2966</th>\n",
       "      <td>Malaysia</td>\n",
       "      <td>United States</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2967</th>\n",
       "      <td>Malaysia</td>\n",
       "      <td>Viet Nam</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4043</th>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>Liberia</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4091</th>\n",
       "      <td>Serbia</td>\n",
       "      <td>Various</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>1150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7889</th>\n",
       "      <td>Israel</td>\n",
       "      <td>Dem. Rep. of the Congo</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>208.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8361</th>\n",
       "      <td>Malaysia</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9441</th>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>Liberia</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10104</th>\n",
       "      <td>The former Yugoslav Rep. of Macedonia</td>\n",
       "      <td>Bosnia and Herzegovina</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11889</th>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>Various</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13223</th>\n",
       "      <td>Israel</td>\n",
       "      <td>Dem. Rep. of the Congo</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>208.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13515</th>\n",
       "      <td>Liberia</td>\n",
       "      <td>Burkina Faso</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13522</th>\n",
       "      <td>Liberia</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13527</th>\n",
       "      <td>Liberia</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13698</th>\n",
       "      <td>Malaysia</td>\n",
       "      <td>Uganda</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14717</th>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>Liberia</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15366</th>\n",
       "      <td>The former Yugoslav Rep. of Macedonia</td>\n",
       "      <td>Bosnia and Herzegovina</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17125</th>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>Various</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18393</th>\n",
       "      <td>Israel</td>\n",
       "      <td>Dem. Rep. of the Congo</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>208.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18675</th>\n",
       "      <td>Liberia</td>\n",
       "      <td>Burkina Faso</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18682</th>\n",
       "      <td>Liberia</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18687</th>\n",
       "      <td>Liberia</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18830</th>\n",
       "      <td>Malaysia</td>\n",
       "      <td>Lao People's Dem. Rep.</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18838</th>\n",
       "      <td>Malaysia</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19809</th>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>Liberia</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20407</th>\n",
       "      <td>The former Yugoslav Rep. of Macedonia</td>\n",
       "      <td>Bosnia and Herzegovina</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22120</th>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>Various</td>\n",
       "      <td>2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7820.0</td>\n",
       "      <td>3724.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23371</th>\n",
       "      <td>Israel</td>\n",
       "      <td>Côte d'Ivoire</td>\n",
       "      <td>2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59870</th>\n",
       "      <td>Romania</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>2004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59871</th>\n",
       "      <td>Romania</td>\n",
       "      <td>Kuwait</td>\n",
       "      <td>2004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59888</th>\n",
       "      <td>Romania</td>\n",
       "      <td>Stateless</td>\n",
       "      <td>2004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60567</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Myanmar</td>\n",
       "      <td>2004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61267</th>\n",
       "      <td>Belarus</td>\n",
       "      <td>Cameroon</td>\n",
       "      <td>2003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62962</th>\n",
       "      <td>Kyrgyzstan</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>2003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63148</th>\n",
       "      <td>Mexico</td>\n",
       "      <td>State of Palestine</td>\n",
       "      <td>2003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63746</th>\n",
       "      <td>Romania</td>\n",
       "      <td>Mauritania</td>\n",
       "      <td>2003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63751</th>\n",
       "      <td>Romania</td>\n",
       "      <td>Rwanda</td>\n",
       "      <td>2003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63757</th>\n",
       "      <td>Romania</td>\n",
       "      <td>Stateless</td>\n",
       "      <td>2003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63889</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>Eritrea</td>\n",
       "      <td>2003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64431</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Islamic Rep. of Iran</td>\n",
       "      <td>2003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64439</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>2003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65614</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>Chile</td>\n",
       "      <td>2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66871</th>\n",
       "      <td>Malaysia</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67364</th>\n",
       "      <td>Panama</td>\n",
       "      <td>Sierra Leone</td>\n",
       "      <td>2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69266</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>Chile</td>\n",
       "      <td>2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69867</th>\n",
       "      <td>Greece</td>\n",
       "      <td>Various</td>\n",
       "      <td>2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2429.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2429.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70115</th>\n",
       "      <td>Israel</td>\n",
       "      <td>Various</td>\n",
       "      <td>2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70960</th>\n",
       "      <td>Romania</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70964</th>\n",
       "      <td>Romania</td>\n",
       "      <td>Mauritania</td>\n",
       "      <td>2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70974</th>\n",
       "      <td>Romania</td>\n",
       "      <td>Stateless</td>\n",
       "      <td>2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71121</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71831</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>Bosnia and Herzegovina</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74111</th>\n",
       "      <td>Romania</td>\n",
       "      <td>Angola</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74116</th>\n",
       "      <td>Romania</td>\n",
       "      <td>Cameroon</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74125</th>\n",
       "      <td>Romania</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74129</th>\n",
       "      <td>Romania</td>\n",
       "      <td>Mauritania</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74139</th>\n",
       "      <td>Romania</td>\n",
       "      <td>Stateless</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74707</th>\n",
       "      <td>Ukraine</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Asylum_Country          Origin_Country  Year  \\\n",
       "2453                                  Israel  Dem. Rep. of the Congo  2016   \n",
       "2941                                Malaysia                   Kenya  2016   \n",
       "2953                                Malaysia         Rep. of Moldova  2016   \n",
       "2966                                Malaysia           United States  2016   \n",
       "2967                                Malaysia                Viet Nam  2016   \n",
       "4043                            Saudi Arabia                 Liberia  2016   \n",
       "4091                                  Serbia                 Various  2016   \n",
       "7889                                  Israel  Dem. Rep. of the Congo  2015   \n",
       "8361                                Malaysia                   Kenya  2015   \n",
       "9441                            Saudi Arabia                 Liberia  2015   \n",
       "10104  The former Yugoslav Rep. of Macedonia  Bosnia and Herzegovina  2015   \n",
       "11889                             Costa Rica                 Various  2014   \n",
       "13223                                 Israel  Dem. Rep. of the Congo  2014   \n",
       "13515                                Liberia            Burkina Faso  2014   \n",
       "13522                                Liberia                   Ghana  2014   \n",
       "13527                                Liberia                 Nigeria  2014   \n",
       "13698                               Malaysia                  Uganda  2014   \n",
       "14717                           Saudi Arabia                 Liberia  2014   \n",
       "15366  The former Yugoslav Rep. of Macedonia  Bosnia and Herzegovina  2014   \n",
       "17125                             Costa Rica                 Various  2013   \n",
       "18393                                 Israel  Dem. Rep. of the Congo  2013   \n",
       "18675                                Liberia            Burkina Faso  2013   \n",
       "18682                                Liberia                   Ghana  2013   \n",
       "18687                                Liberia                 Nigeria  2013   \n",
       "18830                               Malaysia  Lao People's Dem. Rep.  2013   \n",
       "18838                               Malaysia             Philippines  2013   \n",
       "19809                           Saudi Arabia                 Liberia  2013   \n",
       "20407  The former Yugoslav Rep. of Macedonia  Bosnia and Herzegovina  2013   \n",
       "22120                             Costa Rica                 Various  2012   \n",
       "23371                                 Israel           Côte d'Ivoire  2012   \n",
       "...                                      ...                     ...   ...   \n",
       "59870                                Romania                   Kenya  2004   \n",
       "59871                                Romania                  Kuwait  2004   \n",
       "59888                                Romania               Stateless  2004   \n",
       "60567                   United Arab Emirates                 Myanmar  2004   \n",
       "61267                                Belarus                Cameroon  2003   \n",
       "62962                             Kyrgyzstan               Sri Lanka  2003   \n",
       "63148                                 Mexico      State of Palestine  2003   \n",
       "63746                                Romania              Mauritania  2003   \n",
       "63751                                Romania                  Rwanda  2003   \n",
       "63757                                Romania               Stateless  2003   \n",
       "63889                           South Africa                 Eritrea  2003   \n",
       "64431                   United Arab Emirates    Islamic Rep. of Iran  2003   \n",
       "64439                   United Arab Emirates              Uzbekistan  2003   \n",
       "65614                               Colombia                   Chile  2002   \n",
       "66871                               Malaysia               Sri Lanka  2002   \n",
       "67364                                 Panama            Sierra Leone  2002   \n",
       "69266                               Colombia                   Chile  2001   \n",
       "69867                                 Greece                 Various  2001   \n",
       "70115                                 Israel                 Various  2001   \n",
       "70960                                Romania                  Jordan  2001   \n",
       "70964                                Romania              Mauritania  2001   \n",
       "70974                                Romania               Stateless  2001   \n",
       "71121                           South Africa                Zimbabwe  2001   \n",
       "71831                                Algeria  Bosnia and Herzegovina  2000   \n",
       "74111                                Romania                  Angola  2000   \n",
       "74116                                Romania                Cameroon  2000   \n",
       "74125                                Romania                  Jordan  2000   \n",
       "74129                                Romania              Mauritania  2000   \n",
       "74139                                Romania               Stateless  2000   \n",
       "74707                                Ukraine                  Jordan  2000   \n",
       "\n",
       "       Refugees  Refugees_Assisted_by_UNHCR  Refugee_Like_Population  \\\n",
       "2453        NaN                         NaN                    208.0   \n",
       "2941        NaN                         NaN                      1.0   \n",
       "2953        NaN                         NaN                      1.0   \n",
       "2966        NaN                         NaN                      1.0   \n",
       "2967        NaN                         NaN                      1.0   \n",
       "4043        NaN                         NaN                      7.0   \n",
       "4091        NaN                         NaN                   1150.0   \n",
       "7889        NaN                         NaN                    208.0   \n",
       "8361        NaN                         NaN                      1.0   \n",
       "9441        NaN                         NaN                      7.0   \n",
       "10104       NaN                         NaN                      6.0   \n",
       "11889       NaN                         NaN                   1564.0   \n",
       "13223       NaN                         NaN                    208.0   \n",
       "13515       NaN                         NaN                      4.0   \n",
       "13522       NaN                         NaN                      2.0   \n",
       "13527       NaN                         NaN                      1.0   \n",
       "13698       NaN                         NaN                      1.0   \n",
       "14717       NaN                         NaN                     27.0   \n",
       "15366       NaN                         NaN                      6.0   \n",
       "17125       NaN                         NaN                   1564.0   \n",
       "18393       NaN                         NaN                    208.0   \n",
       "18675       NaN                         NaN                      4.0   \n",
       "18682       NaN                         NaN                      2.0   \n",
       "18687       NaN                         NaN                      1.0   \n",
       "18830       NaN                         NaN                      1.0   \n",
       "18838       NaN                         NaN                      7.0   \n",
       "19809       NaN                         NaN                     27.0   \n",
       "20407       NaN                         NaN                      6.0   \n",
       "22120       NaN                         NaN                   7820.0   \n",
       "23371       NaN                         NaN                      3.0   \n",
       "...         ...                         ...                      ...   \n",
       "59870       NaN                         1.0                      NaN   \n",
       "59871       NaN                         1.0                      NaN   \n",
       "59888       NaN                         3.0                      NaN   \n",
       "60567       NaN                         1.0                      NaN   \n",
       "61267       NaN                         1.0                      NaN   \n",
       "62962       NaN                         1.0                      NaN   \n",
       "63148       NaN                         3.0                      NaN   \n",
       "63746       NaN                         1.0                      NaN   \n",
       "63751       NaN                         2.0                      NaN   \n",
       "63757       NaN                         1.0                      NaN   \n",
       "63889       NaN                         2.0                      NaN   \n",
       "64431       NaN                         1.0                      NaN   \n",
       "64439       NaN                         4.0                      NaN   \n",
       "65614       NaN                         4.0                      NaN   \n",
       "66871       NaN                         2.0                      NaN   \n",
       "67364       NaN                         1.0                      NaN   \n",
       "69266       NaN                         4.0                      NaN   \n",
       "69867       NaN                      2429.0                      NaN   \n",
       "70115       NaN                       170.0                      NaN   \n",
       "70960       NaN                         1.0                      NaN   \n",
       "70964       NaN                         1.0                      NaN   \n",
       "70974       NaN                         1.0                      NaN   \n",
       "71121       NaN                         5.0                      NaN   \n",
       "71831       NaN                         1.0                      NaN   \n",
       "74111       NaN                         4.0                      NaN   \n",
       "74116       NaN                        11.0                      NaN   \n",
       "74125       NaN                         1.0                      NaN   \n",
       "74129       NaN                         1.0                      NaN   \n",
       "74139       NaN                         1.0                      NaN   \n",
       "74707       NaN                         1.0                      NaN   \n",
       "\n",
       "       Refugee_Like_Population_Assisted_by_UNHCR  \n",
       "2453                                        50.0  \n",
       "2941                                         1.0  \n",
       "2953                                         1.0  \n",
       "2966                                         1.0  \n",
       "2967                                         1.0  \n",
       "4043                                         7.0  \n",
       "4091                                      1150.0  \n",
       "7889                                        50.0  \n",
       "8361                                         1.0  \n",
       "9441                                         7.0  \n",
       "10104                                        6.0  \n",
       "11889                                      750.0  \n",
       "13223                                       50.0  \n",
       "13515                                        4.0  \n",
       "13522                                        2.0  \n",
       "13527                                        1.0  \n",
       "13698                                        1.0  \n",
       "14717                                       27.0  \n",
       "15366                                        6.0  \n",
       "17125                                      750.0  \n",
       "18393                                       50.0  \n",
       "18675                                        4.0  \n",
       "18682                                        2.0  \n",
       "18687                                        1.0  \n",
       "18830                                        1.0  \n",
       "18838                                        7.0  \n",
       "19809                                       27.0  \n",
       "20407                                        6.0  \n",
       "22120                                     3724.0  \n",
       "23371                                        3.0  \n",
       "...                                          ...  \n",
       "59870                                        1.0  \n",
       "59871                                        1.0  \n",
       "59888                                        3.0  \n",
       "60567                                        1.0  \n",
       "61267                                        1.0  \n",
       "62962                                        1.0  \n",
       "63148                                        3.0  \n",
       "63746                                        1.0  \n",
       "63751                                        2.0  \n",
       "63757                                        1.0  \n",
       "63889                                        2.0  \n",
       "64431                                        1.0  \n",
       "64439                                        4.0  \n",
       "65614                                        4.0  \n",
       "66871                                        2.0  \n",
       "67364                                        1.0  \n",
       "69266                                        4.0  \n",
       "69867                                     2429.0  \n",
       "70115                                      170.0  \n",
       "70960                                        1.0  \n",
       "70964                                        1.0  \n",
       "70974                                        1.0  \n",
       "71121                                        5.0  \n",
       "71831                                        1.0  \n",
       "74111                                        4.0  \n",
       "74116                                       11.0  \n",
       "74125                                        1.0  \n",
       "74129                                        1.0  \n",
       "74139                                        1.0  \n",
       "74707                                        1.0  \n",
       "\n",
       "[198 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def null_check(df, ColumnList):\n",
    "    \"\"\"\n",
    "    Returns rows that contain null values within coulmn list\n",
    "    \n",
    "    Inputs:\n",
    "    df - dataframe\n",
    "    ColumnList - columns to check for nulls\n",
    "    \"\"\"\n",
    "    return df.loc[pd.isnull(df[ColumnList]).any(1),:]\n",
    "\n",
    "# Only state has nulls, which is to be expected.\n",
    "null_check(df = temp_df,\n",
    "           ColumnList = ['Region', 'Country', 'City', 'Date', 'AvgTemperature'])\n",
    "\n",
    "# No null values detected.\n",
    "null_check(df = country_pop_df,\n",
    "           ColumnList = ['Country', 'Year', 'Country_Population'])\n",
    "\n",
    "# No null values detected.\n",
    "null_check(df = city_pop_df,\n",
    "           ColumnList = ['Country', 'Year', 'City', 'City_Type', 'Record_Type',\n",
    "                         'Reliability', 'Source_Year', 'City_Population'])\n",
    "\n",
    "# No unexpected nulls. Not all refugee counts populate, which is okay.\n",
    "null_check(df = refugee_df,\n",
    "           ColumnList = ['Asylum_Country', 'Origin_Country', 'Year',\n",
    "                         'Refugees', 'Refugee_Like_Population'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Define a country naming standard across data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Pull unique country and city values from each source data set\n",
    "unique_refugee_origin = refugee_df[['Origin_Country']].drop_duplicates()\n",
    "\n",
    "unique_refugee_asylum = refugee_df[['Asylum_Country']].drop_duplicates()\n",
    "\n",
    "unique_citypop_country = city_pop_df[['Country']].drop_duplicates()\n",
    "\n",
    "unique_countrypop = country_pop_df[['Country']].drop_duplicates()\n",
    "\n",
    "unique_temp_country = temp_df[['Country']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Channel Islands not found in regex\n",
      "Caribbean small states not found in regex\n",
      "Pacific island small states not found in regex\n",
      "Serbia-Montenegro not found in regex\n",
      "Yugoslavia not found in regex\n",
      "Various not found in regex\n",
      "Stateless not found in regex\n",
      "Various not found in regex\n",
      "Tibetans not found in regex\n"
     ]
    }
   ],
   "source": [
    "def country_standard(df, rename):\n",
    "    \"\"\"\n",
    "    Rename column to be unique across data sources\n",
    "    Convert dataframe to a list\n",
    "    Create a standardized country name and add it to the dataframe\n",
    "    Replace values 'not found' (default designation) with source value\n",
    "    \n",
    "    Inputs:\n",
    "    df - dataframe\n",
    "    rename - new name for the column\n",
    "    \"\"\"\n",
    "    # Rename column to be unique across data sources\n",
    "    df.columns = [rename]\n",
    "    \n",
    "    # Convert dataframe to a list\n",
    "    country_list = df[rename].tolist()\n",
    "    \n",
    "    # Source: https://github.com/konstantinstadler/country_converter\n",
    "    # Create a standardized country name and add it to the dataframe\n",
    "    standard_names = coco.convert(names = country_list, to = 'name_short')\n",
    "    df['CountryStandard'] = standard_names\n",
    "    \n",
    "    # Replace values 'not found' (default designation) with source value\n",
    "    df.CountryStandard[df.CountryStandard == 'not found'] = df[rename]\n",
    "\n",
    "country_standard(df = unique_countrypop, rename = 'Country_CountryPop')\n",
    "country_standard(df = unique_temp_country, rename = 'Country_Temp')\n",
    "country_standard(df = unique_citypop_country, rename = 'Country_CityPop')\n",
    "country_standard(df = unique_refugee_asylum, rename = 'Asylum_Country')\n",
    "country_standard(df = unique_refugee_origin, rename = 'Origin_Country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country_CountryPop</th>\n",
       "      <th>CountryStandard</th>\n",
       "      <th>Country_Temp</th>\n",
       "      <th>Country_CityPop</th>\n",
       "      <th>Asylum_Country</th>\n",
       "      <th>Origin_Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>Aruba</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aruba</td>\n",
       "      <td>Aruba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angola</td>\n",
       "      <td>Angola</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Angola</td>\n",
       "      <td>Angola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Albania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andorra</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country_CountryPop CountryStandard Country_Temp Country_CityPop  \\\n",
       "0              Aruba           Aruba          NaN           Aruba   \n",
       "1        Afghanistan     Afghanistan          NaN             NaN   \n",
       "2             Angola          Angola          NaN             NaN   \n",
       "3            Albania         Albania      Albania         Albania   \n",
       "4            Andorra         Andorra          NaN         Andorra   \n",
       "\n",
       "  Asylum_Country Origin_Country  \n",
       "0          Aruba            NaN  \n",
       "1    Afghanistan    Afghanistan  \n",
       "2         Angola         Angola  \n",
       "3        Albania        Albania  \n",
       "4            NaN        Andorra  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Full outer join dataframes for mapping purposes\n",
    "# Source: https://stackoverflow.com/questions/23668427/pandas-three-way-joining-multiple-dataframes-on-columns\n",
    "dfs = [unique_countrypop,\n",
    "       unique_temp_country,\n",
    "       unique_citypop_country,\n",
    "       unique_refugee_asylum,\n",
    "       unique_refugee_origin]\n",
    "\n",
    "country_map = reduce(lambda left,right: pd.merge(left, right, on = 'CountryStandard', how = 'outer'), dfs)\n",
    "\n",
    "country_map.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Define a city and state naming standard across data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Pull unique country, state, and city values from each applicable source data set\n",
    "unique_citypop_city = city_pop_df[['Country', 'City']].drop_duplicates()\n",
    "\n",
    "unique_citypop_city.columns = ['Country_CityPop', 'City_CityPop']\n",
    "\n",
    "unique_temp_city = temp_df[['Country', 'State', 'City']].drop_duplicates()\n",
    "\n",
    "unique_temp_city.columns = ['Country_Temp', 'State_Temp', 'City_Temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create state and abbreviation mapping dataframe\n",
    "# Source: https://github.com/unitedstates/python-us\n",
    "\n",
    "# Place state and abbreviation in a dictionary\n",
    "state = us.states.mapping('abbr', 'name')\n",
    "\n",
    "# Convert dictionary into a dataframe\n",
    "state_abbr = pd.DataFrame(list(state.items()))\n",
    "state_abbr.columns = ['StateAbbreviation', 'State']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountryStandard</th>\n",
       "      <th>State</th>\n",
       "      <th>StateAbbreviation</th>\n",
       "      <th>Country_CityPop</th>\n",
       "      <th>City_CityPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aland Islands</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>MARIEHAMN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Durrës</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Albania</td>\n",
       "      <td>TIRANA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>Adrar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>Ain Defla</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CountryStandard State StateAbbreviation Country_CityPop City_CityPop\n",
       "0   Aland Islands  None              None   Åland Islands    MARIEHAMN\n",
       "1         Albania  None              None         Albania       Durrës\n",
       "2         Albania  None              None         Albania       TIRANA\n",
       "3         Algeria  None              None         Algeria        Adrar\n",
       "4         Algeria  None              None         Algeria    Ain Defla"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add country standard and state info to both datasets containing cities\n",
    "unique_temp_city = sqldf(\"\"\"\n",
    "    SELECT DISTINCT \n",
    "        country_map.CountryStandard,\n",
    "        state_abbr.StateAbbreviation,\n",
    "        temp.*\n",
    "    FROM unique_temp_city as temp\n",
    "    LEFT JOIN country_map\n",
    "        ON country_map.Country_Temp = temp.Country_Temp\n",
    "    LEFT JOIN state_abbr\n",
    "        ON temp.State_Temp = state_abbr.State\n",
    "    \"\"\")\n",
    "\n",
    "unique_citypop_city = sqldf(\"\"\"\n",
    "    SELECT DISTINCT \n",
    "        country_map.CountryStandard,\n",
    "        State, \n",
    "        StateAbbreviation,\n",
    "        CityPop.*\n",
    "    FROM unique_citypop_city AS CityPop\n",
    "    LEFT JOIN country_map\n",
    "        ON country_map.Country_CityPop = CityPop.Country_CityPop\n",
    "    LEFT JOIN state_abbr\n",
    "        ON SUBSTR(CityPop.City_CityPop, length(CityPop.City_CityPop) - 2, 2) = state_abbr.StateAbbreviation\n",
    "            AND country_map.CountryStandard = 'United States'\n",
    "    \"\"\")\n",
    "\n",
    "unique_citypop_city.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Build mapping for state, city, and country standards\n",
    "# The termperature source joins to the city poulation source several times\n",
    "# to populate the city field as best as possible without too much hardcoding.\n",
    "temp_city_map = sqldf(\"\"\"\n",
    "    SELECT DISTINCT \n",
    "        unique_temp_city.CountryStandard as CountryStandard,\n",
    "        unique_temp_city.Country_Temp,\n",
    "        --unique_citypop_city.Country_CityPop,\n",
    "        unique_temp_city.State_Temp as StateStandard,\n",
    "        unique_temp_city.State_Temp,\n",
    "        --COALESCE(CityUS.State, CityUSPartial.State) as State_CityPop,\n",
    "        unique_temp_city.City_Temp as CityStandard,\n",
    "        unique_temp_city.City_Temp,\n",
    "        -- unique_citypop_city.City_CityPop,\n",
    "        -- CityUS.City_CityPop as CityUS,\n",
    "        -- CityUSPartial.City_CityPop as CityUSPartial,\n",
    "        -- partial6.City_CityPop as CityPartial6,\n",
    "        -- partial5.City_CityPop as CityPartial5,\n",
    "        -- partial4.City_CityPop as CityPartial4,\n",
    "        -- partial3.City_CityPop as CityPartial3,\n",
    "        COALESCE(unique_citypop_city.City_CityPop, CityUS.City_CityPop, CityUSPartial.City_CityPop, \n",
    "                 partial6.City_CityPop, partial5.City_CityPop, partial4.City_CityPop, partial3.City_CityPop) AS City_CityPop\n",
    "    FROM unique_temp_city\n",
    "    -- Join on city (case protected) and country\n",
    "    LEFT JOIN unique_citypop_city\n",
    "        ON UPPER(unique_citypop_city.City_CityPop) = UPPER(unique_temp_city.City_Temp)\n",
    "            AND unique_citypop_city.CountryStandard = unique_temp_city.CountryStandard\n",
    "    -- Strip the US abbreviation at the end of the city \n",
    "    -- and join on city, state, and country (US only)\n",
    "    LEFT JOIN unique_citypop_city AS CityUS\n",
    "        ON SUBSTR(UPPER(CityUS.City_CityPop),1,length(CityUS.City_CityPop) - 5) = UPPER(unique_temp_city.City_Temp)\n",
    "            AND CityUS.CountryStandard = unique_temp_city.CountryStandard\n",
    "            AND CityUS.State = unique_temp_city.State_Temp\n",
    "            AND unique_temp_city.CountryStandard = 'United States'\n",
    "            AND unique_citypop_city.City_CityPop IS NULL\n",
    "    -- Join on city matching the first five characters, state, and country (US only)\n",
    "    LEFT JOIN unique_citypop_city AS CityUSPartial\n",
    "        ON SUBSTR(UPPER(CityUSPartial.City_CityPop),1,5) = SUBSTR(UPPER(unique_temp_city.City_Temp),1,5)\n",
    "            AND CityUSPartial.CountryStandard = unique_temp_city.CountryStandard\n",
    "            AND CityUSPartial.State = unique_temp_city.State_Temp\n",
    "            AND unique_temp_city.CountryStandard = 'United States'\n",
    "            AND unique_citypop_city.City_CityPop IS NULL\n",
    "            AND CityUS.City_CityPop IS NULL\n",
    "    -- Join on city matching the first six characters, state, and country (non US)\n",
    "    LEFT JOIN unique_citypop_city AS partial6\n",
    "        ON SUBSTR(UPPER(partial6.City_CityPop),1,6) = SUBSTR(UPPER(unique_temp_city.City_Temp),1,6)\n",
    "            AND partial6.CountryStandard = unique_temp_city.CountryStandard\n",
    "            AND unique_temp_city.CountryStandard <> 'United States'\n",
    "            AND unique_citypop_city.City_CityPop IS NULL\n",
    "            AND CityUS.City_CityPop IS NULL\n",
    "            AND CityUSPartial.City_CityPop IS NULL\n",
    "    -- Join on city matching the first five characters, state, and country (non US)\n",
    "    LEFT JOIN unique_citypop_city AS partial5\n",
    "        ON SUBSTR(UPPER(partial5.City_CityPop),1,5) = SUBSTR(UPPER(unique_temp_city.City_Temp),1,5)\n",
    "            AND partial5.CountryStandard = unique_temp_city.CountryStandard\n",
    "            AND unique_temp_city.CountryStandard <> 'United States'\n",
    "            AND unique_citypop_city.City_CityPop IS NULL\n",
    "            AND CityUS.City_CityPop IS NULL\n",
    "            AND CityUSPartial.City_CityPop IS NULL\n",
    "            AND partial6.City_CityPop IS NULL\n",
    "    -- Join on city matching the first four characters, state, and country (non US)\n",
    "    LEFT JOIN unique_citypop_city AS partial4\n",
    "        ON SUBSTR(UPPER(partial4.City_CityPop),1,4) = SUBSTR(UPPER(unique_temp_city.City_Temp),1,4)\n",
    "            AND partial4.CountryStandard = unique_temp_city.CountryStandard\n",
    "            AND unique_temp_city.CountryStandard <> 'United States'\n",
    "            AND unique_citypop_city.City_CityPop IS NULL\n",
    "            AND CityUS.City_CityPop IS NULL\n",
    "            AND CityUSPartial.City_CityPop IS NULL\n",
    "            AND partial6.City_CityPop IS NULL\n",
    "            AND partial5.City_CityPop IS NULL\n",
    "    -- Join on city matching the first three characters, state, and country (non US)\n",
    "    LEFT JOIN unique_citypop_city AS partial3\n",
    "        ON SUBSTR(UPPER(partial3.City_CityPop),1,3) = SUBSTR(UPPER(unique_temp_city.City_Temp),1,3)\n",
    "            AND partial3.CountryStandard = unique_temp_city.CountryStandard\n",
    "            AND unique_temp_city.CountryStandard <> 'United States'\n",
    "            AND partial3.City_CityPop NOT IN ('BELMOPAN', 'Bommanahalli', 'Brugge')\n",
    "            AND unique_citypop_city.City_CityPop IS NULL\n",
    "            AND CityUS.City_CityPop IS NULL\n",
    "            AND CityUSPartial.City_CityPop IS NULL\n",
    "            AND partial6.City_CityPop IS NULL\n",
    "            AND partial5.City_CityPop IS NULL\n",
    "            AND partial4.City_CityPop IS NULL\n",
    "    --WHERE unique_citypop_city.City_CityPop IS NULL \n",
    "    --    and CityUS is null\n",
    "    --    and CityUSPartial is not null\n",
    "      --  and partial6.City_CityPop IS NULL\n",
    "      --  and partial5.City_CityPop IS NULL\n",
    "      --  and partial4.City_CityPop IS NULL\n",
    "      --  and partial3.City_CityPop IS not NULL\n",
    "    ORDER BY unique_temp_city.City_Temp\n",
    "    \"\"\")\n",
    "\n",
    "# 109/321 link on initial join\n",
    "# 211/321 link with second join added\n",
    "# 235/321 link with third join added\n",
    "# 244/321 link with fourth join added\n",
    "# 249/321 link with fifth join added\n",
    "# 253/321 link with sixth join added\n",
    "# 264/321 link with seventh join added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Join mapping to city population set to have standard naming across\n",
    "citypop_city_map = sqldf(\"\"\"\n",
    "    SELECT DISTINCT \n",
    "        CityPop.CountryStandard,\n",
    "        COALESCE(temp_city_map.StateStandard, CityPop.State) as StateStandard,\n",
    "        COALESCE(temp_city_map.CityStandard, CityPop.City_CityPop) as CityStandard, \n",
    "        CityPop.Country_CityPop,\n",
    "        CityPop.State as State_CityPop,\n",
    "        CityPop.City_CityPop\n",
    "    FROM unique_citypop_city AS CityPop\n",
    "    LEFT JOIN temp_city_map\n",
    "        ON CityPop.City_CityPop = temp_city_map.City_CityPop\n",
    "            AND CityPop.CountryStandard = temp_city_map.CountryStandard\n",
    "    \"\"\")\n",
    "\n",
    "# Propercase the city standard, so it's clean in presentation\n",
    "citypop_city_map[\"CityStandard\"] = citypop_city_map[\"CityStandard\"].str.title()\n",
    "\n",
    "# Drop city name to avoid duplicate fields in the proceeding step\n",
    "temp_city_map = temp_city_map.drop(columns=['City_CityPop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountryStandard</th>\n",
       "      <th>Country_Temp</th>\n",
       "      <th>StateStandard</th>\n",
       "      <th>State_Temp</th>\n",
       "      <th>CityStandard</th>\n",
       "      <th>City_Temp</th>\n",
       "      <th>Country_CityPop</th>\n",
       "      <th>State_CityPop</th>\n",
       "      <th>City_CityPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cote d'Ivoire</td>\n",
       "      <td>Ivory Coast</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Abidjan</td>\n",
       "      <td>Abidjan</td>\n",
       "      <td>Côte d'Ivoire</td>\n",
       "      <td>None</td>\n",
       "      <td>Abidjan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Abilene (TX)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Addis Ababa</td>\n",
       "      <td>Addis Ababa</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>None</td>\n",
       "      <td>ADDIS ABABA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>Akron Canton</td>\n",
       "      <td>Akron Canton</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>Akron (OH)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CountryStandard          Country_Temp StateStandard State_Temp  \\\n",
       "0         Cote d'Ivoire           Ivory Coast          None       None   \n",
       "1         United States                    US         Texas      Texas   \n",
       "2  United Arab Emirates  United Arab Emirates          None       None   \n",
       "3              Ethiopia              Ethiopia          None       None   \n",
       "4         United States                    US          Ohio       Ohio   \n",
       "\n",
       "   CityStandard     City_Temp           Country_CityPop State_CityPop  \\\n",
       "0       Abidjan       Abidjan             Côte d'Ivoire          None   \n",
       "1       Abilene       Abilene  United States of America         Texas   \n",
       "2     Abu Dhabi     Abu Dhabi                       NaN           NaN   \n",
       "3   Addis Ababa   Addis Ababa                  Ethiopia          None   \n",
       "4  Akron Canton  Akron Canton  United States of America          Ohio   \n",
       "\n",
       "   City_CityPop  \n",
       "0       Abidjan  \n",
       "1  Abilene (TX)  \n",
       "2           NaN  \n",
       "3   ADDIS ABABA  \n",
       "4    Akron (OH)  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Full outer join on city maps\n",
    "city_map = pd.merge(temp_city_map, citypop_city_map, on=['CityStandard', 'CountryStandard', 'StateStandard'], how='outer')\n",
    "city_map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Remove city population source content from temperature mapping\n",
    "temp_city_map = temp_city_map[['Country_Temp', 'State_Temp', 'City_Temp',\n",
    "                               'CountryStandard', 'StateStandard', 'CityStandard']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Transform the source datasets to have standardized names\n",
    "staging_temp = sqldf(\"\"\"\n",
    "    SELECT \n",
    "        temp_df.Region,\n",
    "        temp_city_map.CountryStandard,\n",
    "        temp_city_map.StateStandard,\n",
    "        temp_city_map.CityStandard,\n",
    "        temp_df.Month,\n",
    "        temp_df.Day,\n",
    "        temp_df.Year,\n",
    "        temp_df.AvgTemperature,\n",
    "        temp_df.Date,\n",
    "        temp_df.DateKey\n",
    "    FROM temp_df\n",
    "    LEFT JOIN temp_city_map\n",
    "        ON temp_df.Country = temp_city_map.Country_Temp\n",
    "            AND Coalesce(temp_df.State, 'State') = Coalesce(temp_city_map.State_Temp, 'State')\n",
    "            AND temp_df.City = temp_city_map.City_Temp\n",
    "    \"\"\")\n",
    "\n",
    "staging_country_pop = sqldf(\"\"\"\n",
    "    SELECT \n",
    "        country_map.CountryStandard,\n",
    "        country_pop_df.Year,\n",
    "        country_pop_df.Country_Population\n",
    "    FROM country_pop_df\n",
    "    LEFT JOIN country_map\n",
    "        ON country_pop_df.Country = country_map.Country_CountryPop\n",
    "    \"\"\")\n",
    "\n",
    "staging_city_pop = sqldf(\"\"\"\n",
    "    SELECT \n",
    "        city_map.CountryStandard,\n",
    "        city_map.StateStandard,\n",
    "        city_pop_df.Year,\n",
    "        city_map.CityStandard,\n",
    "        city_pop_df.City_Type,\n",
    "        city_pop_df.Record_Type,\n",
    "        city_pop_df.Reliability,\n",
    "        city_pop_df.Source_Year,\n",
    "        city_pop_df.City_Population,\n",
    "        city_pop_df.Population_Notes\n",
    "    FROM city_pop_df\n",
    "    LEFT JOIN citypop_city_map AS city_map\n",
    "        ON city_pop_df.Country = city_map.Country_CityPop\n",
    "            AND city_pop_df.City = city_map.City_CityPop\n",
    "    \"\"\")\n",
    "\n",
    "staging_refugee = sqldf(\"\"\"\n",
    "    SELECT \n",
    "        Asylum.CountryStandard as AsylumCountry,\n",
    "        Origin.CountryStandard as OriginCountry,\n",
    "        refugee_df.Year,\n",
    "        refugee_df.Refugees,\n",
    "        refugee_df.Refugees_Assisted_by_UNHCR,\n",
    "        refugee_df.Refugee_Like_Population,\n",
    "        refugee_df.Refugee_Like_Population_Assisted_by_UNHCR\n",
    "    FROM refugee_df\n",
    "    LEFT JOIN country_map AS Asylum\n",
    "        ON refugee_df.Asylum_Country = Asylum.Asylum_Country\n",
    "    LEFT JOIN country_map AS Origin\n",
    "        ON refugee_df.Origin_Country = Origin.Origin_Country\n",
    "    \"\"\")\n",
    "\n",
    "# Define source_dfs list for function used below.\n",
    "source_dfs = [staging_temp,\n",
    "              staging_country_pop,\n",
    "              staging_city_pop,\n",
    "              staging_refugee]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create S3 buckets that reflect the path designs designated in dwh.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in parameters needed for Redshift cluster\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dwh.cfg')\n",
    "\n",
    "# Define bucket name and buffer\n",
    "bucket = 'capstone-refugee'\n",
    "csv_buffer = StringIO()\n",
    "\n",
    "# Connect to S3\n",
    "s3 = boto3.resource('s3',\n",
    "                       region_name = \"us-west-2\",\n",
    "                       aws_access_key_id = config.get('AWS','KEY'),\n",
    "                       aws_secret_access_key = config.get('AWS','SECRET')\n",
    "                   )\n",
    "\n",
    "# Create S3 buckets\n",
    "# s3.create_bucket(Bucket = bucket, CreateBucketConfiguration={\n",
    "#     'LocationConstraint': 'us-west-2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define s3_files for function below. \n",
    "# Make sure they align with source_dfs list.\n",
    "s3_files = ['temperature/staging_temp.csv',\n",
    "            'country_poulation/staging_country_pop.csv',\n",
    "            'city_population/staging_city_pop.csv',\n",
    "            'refugee/staging_refugee.csv']\n",
    "\n",
    "def df_to_s3():\n",
    "    \"\"\"\n",
    "    Write the dataframe to csv is buffer\n",
    "    Store the csv content into the s3 path\n",
    "    Go to the beginning of the buffer and reset content\n",
    "    \"\"\"\n",
    "    \n",
    "    # For each source df and s3 path\n",
    "    for df, file in list(zip(source_dfs, s3_files)):\n",
    "        # Write the dataframe to csv is buffer\n",
    "        df.to_csv(csv_buffer, index = False)\n",
    "        \n",
    "        # Store the csv content into the s3 path\n",
    "        s3.Object(bucket, file).put(Body = csv_buffer.getvalue())\n",
    "        \n",
    "        # Go to the beginning of the buffer and reset content\n",
    "        csv_buffer.seek(0)\n",
    "        csv_buffer.truncate(0)\n",
    "\n",
    "# Call the function\n",
    "df_to_s3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "The data warehouse will reflect a relational data model with a star schema. The relational model complements the use case of analytical processes, especially with expected changes in business requirements over time. Utilizing a dimensional model gives end users an intuitive layout, the flexibility to use SQL, and high data integrity.\n",
    "\n",
    "Fact Tables\n",
    " 1. **TemperatureFact** - records from the temperature dataset associated with daily average temperatures in cities around the world\n",
    "     - TemperatureKey, AvgTemperature, DateKey, CountryKey, CityKey\n",
    " 2. **CountryPopulationFact** - records from the country population dataset reflecting population counts by year and country\n",
    "     - CountryPopulationKey, CountryPopulation,  CountryKey\n",
    " 3. **CityPopulationFact** - records from the city population dataset reflecting population counts by year and city\n",
    "     - CityPopulationKey, CityPopulation, SourceKey, CityKey,  CountryKey\n",
    " 4. **RefugeeFact** - records from the refugee dataset associated with refugee and refugee-like populations by country and year\n",
    "     - RefugeeKey,  RefugeePopulation, RefugeesAssistedByUNHCR, RefugeeLikePopulation, RefugeeLikePopulationAssistedByUNHCR, AsylumCountryKey, OriginCountryKey\n",
    "\n",
    "Dimension Tables\n",
    " 1. **DateDim** - dates of temperature recordings\n",
    "     - DateKey, Date, Month, Day, Year\n",
    " 2. **CountryDim** - country, year, and region content in climate refugee database\n",
    "     - CountryKey, Country, Region, Year\n",
    " 3. **CityDim** - city, year, and state content in climate refugee database\n",
    "     - CityKey, City, CityType, State, Year\n",
    " 4. **SourceDim** - source details in climate refugee database\n",
    "     - SourceKey, SourceYear, CityPopulationNotes, RecordType, Reliability\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "**Create Table Schemas Based on Conceptual Model**\n",
    " 1. Write create table and drop table statements\n",
    " 2. Add logic to connect the tables to the Amazon Redshift database\n",
    " 3. Launch a Redshift cluster and attach an IAM role with S3 read access\n",
    " 4. Add the cluster and IAM role content to dwh.cfg\n",
    " 5. Test execution by verifying the empty tables exist in the Redshift database\n",
    " \n",
    "**Build ETL Pipeline**\n",
    " 1. Create an S3 bucket and load the source data sets into S3\n",
    " 2. Stage source datasets from S3 into the analytics database\n",
    " 3. Transform the staged datasets into tables reflecting the conceptual model\n",
    " 4. Load the tables into the analytics database\n",
    " 5. Perform data quality checks and revise accordingly as needed\n",
    " 6. Once finished, delete the redshift cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Table list used to drop tables\n",
    "table_list = ['staging_temperatures',\n",
    "              'staging_country_populations',\n",
    "              'staging_city_populations',\n",
    "              'staging_refugees',\n",
    "              'TemperatureFact',\n",
    "              'CountryPopulationFact',\n",
    "              'CityPopulationFact',\n",
    "              'RefugeeFact',\n",
    "              'DateDim',\n",
    "              'CountryDim',\n",
    "              'CityDim',\n",
    "              'SourceDim']\n",
    "\n",
    "def drop_tables(cur, conn):\n",
    "    \"\"\"\n",
    "    Drops each table if they exist for each table in table_list\n",
    "    \n",
    "    INPUTS:\n",
    "    * cur - the cursor available\n",
    "    * conn - database connection\n",
    "    \"\"\"\n",
    "    for table in table_list:\n",
    "        cur.execute(\"DROP TABLE IF EXISTS \" + table)\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create tables\n",
    "create_staging_temperatures = (\"\"\"CREATE TABLE IF NOT EXISTS staging_temperatures(\n",
    "                                      Region varchar NOT NULL,\n",
    "                                      Country varchar NOT NULL distkey,\n",
    "                                      State varchar,\n",
    "                                      City varchar NOT NULL,\n",
    "                                      Month int NOT NULL,\n",
    "                                      Day int NOT NULL,\n",
    "                                      Year int NOT NULL,\n",
    "                                      AvgTemperature decimal NOT NULL,\n",
    "                                      Date date NOT NULL,\n",
    "                                      DateKey int NOT NULL)\"\"\")\n",
    "\n",
    "create_staging_country_populations = (\"\"\"CREATE TABLE IF NOT EXISTS staging_country_populations(\n",
    "                                             Country varchar NOT NULL distkey,\n",
    "                                             Year int NOT NULL,\n",
    "                                             CountryPopulation int NOT NULL)\"\"\")\n",
    "\n",
    "create_staging_city_populations = (\"\"\"CREATE TABLE IF NOT EXISTS staging_city_populations(\n",
    "                                          Country varchar NOT NULL distkey,\n",
    "                                          State varchar,\n",
    "                                          Year int NOT NULL,\n",
    "                                          City varchar NOT NULL,\n",
    "                                          CityType varchar NOT NULL,\n",
    "                                          RecordType varchar NOT NULL,\n",
    "                                          Reliability varchar NOT NULL,\n",
    "                                          SourceYear int NOT NULL,\n",
    "                                          CityPopulation int NOT NULL,\n",
    "                                          PopulationNotesKey varchar NOT NULL)\"\"\")\n",
    "\n",
    "create_staging_refugees = (\"\"\"CREATE TABLE IF NOT EXISTS staging_refugees(\n",
    "                                  AsylumCountry varchar NOT NULL distkey,\n",
    "                                  OriginCountry varchar NOT NULL,\n",
    "                                  Year int NOT NULL,\n",
    "                                  RefugeePopulation decimal,\n",
    "                                  RefugeesAssistedByUNHCR decimal,\n",
    "                                  RefugeeLikePopulation decimal,\n",
    "                                  RefugeeLikePopulationAssistedByUNHCR decimal)\"\"\")\n",
    "\n",
    "create_TemperatureFact = (\"\"\"CREATE TABLE IF NOT EXISTS TemperatureFact(\n",
    "                                 TemperatureKey int IDENTITY(0,1),\n",
    "                                 DateKey int NOT NULL REFERENCES DateDim sortkey,\n",
    "                                 CountryKey int NOT NULL REFERENCES CountryDim,\n",
    "                                 CityKey int NOT NULL REFERENCES CityDim,\n",
    "                                 AvgTemperature decimal NOT NULL,\n",
    "                                 PRIMARY KEY(TemperatureKey))\"\"\")\n",
    "\n",
    "create_CountryPopulationFact = (\"\"\"CREATE TABLE IF NOT EXISTS CountryPopulationFact(\n",
    "                                       CountryPopulationKey int IDENTITY(0,1),\n",
    "                                       CountryPopulation int NOT NULL,\n",
    "                                       CountryKey int NOT NULL REFERENCES CountryDim sortkey,\n",
    "                                       PRIMARY KEY(CountryPopulationKey))\"\"\")\n",
    "\n",
    "create_CityPopulationFact = (\"\"\"CREATE TABLE IF NOT EXISTS CityPopulationFact(\n",
    "                                    CityPopulationKey int IDENTITY(0,1),\n",
    "                                    CityPopulation int NOT NULL,\n",
    "                                    CityKey int NOT NULL REFERENCES CityDim sortkey,\n",
    "                                    CountryKey int NOT NULL REFERENCES CountryDim,\n",
    "                                    SourceKey int NOT NULL REFERENCES SourceDim,\n",
    "                                    PRIMARY KEY(CityPopulationKey))\"\"\")\n",
    "\n",
    "create_RefugeeFact = (\"\"\"CREATE TABLE IF NOT EXISTS RefugeeFact(\n",
    "                             RefugeeKey int IDENTITY(0,1),\n",
    "                             RefugeePopulation int,\n",
    "                             RefugeesAssistedByUNHCR int,\n",
    "                             RefugeeLikePopulation int,\n",
    "                             RefugeeLikePopulationAssistedByUNHCR int,\n",
    "                             AsylumCountryKey int NOT NULL REFERENCES CountryDim sortkey,\n",
    "                             OriginCountryKey int NOT NULL REFERENCES CountryDim,\n",
    "                             PRIMARY KEY(RefugeeKey))\"\"\")\n",
    "\n",
    "create_DateDim = (\"\"\"CREATE TABLE IF NOT EXISTS DateDim(\n",
    "                         DateKey int sortkey,\n",
    "                         Date date,\n",
    "                         Month int,\n",
    "                         Day int,\n",
    "                         Year int,\n",
    "                         PRIMARY KEY(DateKey))\n",
    "                         diststyle all\"\"\")\n",
    "\n",
    "create_CountryDim = (\"\"\"CREATE TABLE IF NOT EXISTS CountryDim(\n",
    "                            CountryKey int sortkey IDENTITY(0,1),\n",
    "                            Country varchar NOT NULL,\n",
    "                            Region varchar NOT NULL,\n",
    "                            Year int NOT NULL,\n",
    "                            PRIMARY KEY(CountryKey))\n",
    "                            diststyle all\"\"\")\n",
    "\n",
    "create_CityDim = (\"\"\"CREATE TABLE IF NOT EXISTS CityDim(\n",
    "                            CityKey int sortkey IDENTITY(0,1),\n",
    "                            City varchar NOT NULL,\n",
    "                            CityType varchar,\n",
    "                            State varchar,\n",
    "                            Year int NOT NULL,\n",
    "                            PRIMARY KEY(CityKey))\n",
    "                            diststyle all\"\"\")\n",
    "\n",
    "create_SourceDim = (\"\"\"CREATE TABLE IF NOT EXISTS SourceDim(\n",
    "                           SourceKey int sortkey IDENTITY(0,1),\n",
    "                           Reliability varchar NOT NULL,\n",
    "                           RecordType varchar NOT NULL,\n",
    "                           CityPopulationNotes varchar,\n",
    "                           SourceYear int NOT NULL,\n",
    "                           PRIMARY KEY(SourceKey))\n",
    "                           diststyle all\"\"\")\n",
    "\n",
    "# Create table query list\n",
    "create_table_queries = [create_staging_temperatures,\n",
    "                        create_staging_country_populations,\n",
    "                        create_staging_city_populations,\n",
    "                        create_staging_refugees,\n",
    "                        create_DateDim,\n",
    "                        create_CountryDim,\n",
    "                        create_CityDim,\n",
    "                        create_SourceDim,\n",
    "                        create_TemperatureFact,\n",
    "                        create_CountryPopulationFact,\n",
    "                        create_CityPopulationFact,\n",
    "                        create_RefugeeFact]\n",
    "\n",
    "def create_tables(cur, conn):\n",
    "    \"\"\"\n",
    "    Creates each table if they don't already exist by executing the \\\n",
    "    queries in `create_table_queries` list from sql_queries.py\n",
    "    \n",
    "    INPUTS:\n",
    "    * cur - the cursor available\n",
    "    * conn - database connection\n",
    "    \"\"\"\n",
    "    for query in create_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Connect to Redshift cluster and gets cursor to it\n",
    "conn = psycopg2.connect(\"\"\"host={} \n",
    "                           dbname={} \n",
    "                           user={} \n",
    "                           password={} \n",
    "                           port={}\"\"\".format(*config['CLUSTER'].values()))\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drops all tables by calling the drop_tables function\n",
    "drop_tables(cur, conn)\n",
    "\n",
    "# Creates all tables by calling the create_tables function\n",
    "create_tables(cur, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Staging table names\n",
    "staging_tables = ['staging_temperatures',\n",
    "                  'staging_country_populations',\n",
    "                  'staging_city_populations',\n",
    "                  'staging_refugees']\n",
    "\n",
    "# Paths to source csv files in S3\n",
    "s3_storage_paths = ['TEMP_DATA',\n",
    "                    'COUNTRY_POP_DATA',\n",
    "                    'CITY_POP_DATA',\n",
    "                    'REFUGEE_DATA']\n",
    "\n",
    "def load_staging_tables(cur, conn):\n",
    "    \"\"\"\n",
    "    Copy source datasets from S3 to Redshift\n",
    "\n",
    "    INPUTS:\n",
    "    * cur - the cursor available\n",
    "    * conn - database connection\n",
    "    \"\"\"\n",
    "    for table, path in list(zip(staging_tables, s3_storage_paths)):\n",
    "        cur.execute((\"\"\"COPY {} FROM {}\n",
    "                        CREDENTIALS 'aws_iam_role={}'\n",
    "                        csv REGION 'us-west-2'\n",
    "                        IGNOREHEADER 1\n",
    "                     \"\"\").format(table,\n",
    "                                 config.get('S3', path),\n",
    "                                 config.get('IAM_ROLE', 'ARN')))\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Loads all staging tables by calling the load_staging_tables function\n",
    "load_staging_tables(cur, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Transform the staged datasets into tables reflecting the conceptual model\n",
    "\n",
    "insert_DateDim = (\"\"\"\n",
    "    INSERT INTO DateDim(DateKey, Date, Month, Day, Year)\n",
    "    SELECT DISTINCT\n",
    "        DateKey,\n",
    "        Date,\n",
    "        Month,\n",
    "        Day,\n",
    "        Year\n",
    "    FROM staging_temperatures\n",
    "    \"\"\")\n",
    "\n",
    "insert_CountryDim = (\"\"\"\n",
    "    INSERT INTO CountryDim(Country, Region, Year)\n",
    "    SELECT DISTINCT\n",
    "        Country,\n",
    "        max(Region) over(partition by Country) as Region,\n",
    "        Year\n",
    "    FROM (SELECT DISTINCT \n",
    "              Country,\n",
    "              Region,\n",
    "              Year \n",
    "          FROM staging_temperatures\n",
    "          UNION\n",
    "          SELECT DISTINCT \n",
    "              Country,\n",
    "              '' as Region,\n",
    "              Year \n",
    "          FROM staging_city_populations\n",
    "          UNION\n",
    "          SELECT DISTINCT \n",
    "              Country,\n",
    "              '' as Region,\n",
    "              Year \n",
    "          FROM staging_country_populations\n",
    "          UNION\n",
    "          SELECT DISTINCT \n",
    "              AsylumCountry,\n",
    "              '' as Region,\n",
    "              Year \n",
    "          FROM staging_refugees\n",
    "          UNION\n",
    "          SELECT DISTINCT \n",
    "              OriginCountry,\n",
    "              '' as Region,\n",
    "              Year \n",
    "          FROM staging_refugees\n",
    "         ) AS CountryInfo  \n",
    "    \"\"\")\n",
    "\n",
    "insert_CityDim = (\"\"\"\n",
    "    INSERT INTO CityDim(City, CityType, State, Year)\n",
    "    SELECT DISTINCT\n",
    "        Coalesce(city_pop.City, temp.City) as City,\n",
    "        CityType,\n",
    "        Coalesce(city_pop.State, temp.State) as State,\n",
    "        Coalesce(city_pop.Year, temp.Year) as Year\n",
    "    FROM staging_city_populations as city_pop\n",
    "    FULL OUTER JOIN staging_temperatures as temp\n",
    "        ON city_pop.City = temp.City\n",
    "            AND Coalesce(city_pop.State, 'State') = Coalesce(temp.State, 'State')\n",
    "            AND city_pop.Year = temp.Year\n",
    "    \"\"\")\n",
    "\n",
    "insert_SourceDim = (\"\"\"\n",
    "    INSERT INTO SourceDim(Reliability, RecordType, CityPopulationNotes, SourceYear)\n",
    "    SELECT DISTINCT\n",
    "        Reliability,\n",
    "        RecordType,\n",
    "        PopulationNotesKey as CityPopulationNotes,\n",
    "        SourceYear\n",
    "    FROM staging_city_populations\n",
    "    \"\"\")\n",
    "\n",
    "insert_TemperatureFact = (\"\"\"\n",
    "    INSERT INTO TemperatureFact(DateKey, CountryKey, CityKey, AvgTemperature)\n",
    "    SELECT DISTINCT\n",
    "        DateDim.DateKey,\n",
    "        CountryDim.CountryKey,\n",
    "        CityDim.CityKey,\n",
    "        temp.AvgTemperature\n",
    "    FROM staging_temperatures as temp\n",
    "    LEFT JOIN DateDim\n",
    "        ON temp.Date = DateDim.Date\n",
    "    LEFT JOIN CountryDim\n",
    "        ON temp.Country = CountryDim.Country\n",
    "            AND temp.Year = CountryDim.Year\n",
    "    LEFT JOIN CityDim\n",
    "        ON temp.City = CityDim.City\n",
    "            AND Coalesce(temp.State, 'State') = Coalesce(CityDim.State, 'State')\n",
    "            AND temp.Year = CityDim.Year\n",
    "    \"\"\")\n",
    "\n",
    "insert_CountryPopulationFact = (\"\"\"\n",
    "    INSERT INTO CountryPopulationFact(CountryPopulation, CountryKey)\n",
    "    SELECT DISTINCT\n",
    "        country_pop.CountryPopulation,\n",
    "        CountryDim.CountryKey\n",
    "    FROM staging_country_populations as country_pop\n",
    "    LEFT JOIN CountryDim\n",
    "        ON country_pop.Country = CountryDim.Country\n",
    "            AND country_pop.Year = CountryDim.Year\n",
    "    \"\"\")\n",
    "\n",
    "insert_CityPopulationFact = (\"\"\"\n",
    "    INSERT INTO CityPopulationFact(CityPopulation, CityKey, CountryKey, SourceKey)\n",
    "    SELECT\n",
    "        city_pop.CityPopulation,\n",
    "        CityDim.CityKey,\n",
    "        CountryDim.CountryKey,\n",
    "        SourceDim.SourceKey\n",
    "    FROM staging_city_populations as city_pop\n",
    "    LEFT JOIN SourceDim\n",
    "        ON city_pop.Reliability = SourceDim.Reliability\n",
    "            AND city_pop.RecordType = SourceDim.RecordType\n",
    "            AND city_pop.PopulationNotesKey = SourceDim.CityPopulationNotes\n",
    "            AND city_pop.SourceYear = SourceDim.SourceYear\n",
    "    LEFT JOIN CountryDim\n",
    "        ON city_pop.Country = CountryDim.Country\n",
    "            AND city_pop.Year = CountryDim.Year\n",
    "    LEFT JOIN CityDim\n",
    "        ON city_pop.City = CityDim.City\n",
    "            AND Coalesce(city_pop.State, 'State') = Coalesce(CityDim.State, 'State')\n",
    "            AND city_pop.Year = CityDim.Year\n",
    "    \"\"\")\n",
    "\n",
    "insert_RefugeeFact = (\"\"\"\n",
    "    INSERT INTO RefugeeFact(RefugeePopulation, RefugeesAssistedByUNHCR, RefugeeLikePopulation,\n",
    "                            RefugeeLikePopulationAssistedByUNHCR, AsylumCountryKey, OriginCountryKey)\n",
    "    SELECT DISTINCT\n",
    "        staging_refugees.RefugeePopulation,\n",
    "        staging_refugees.RefugeesAssistedByUNHCR,\n",
    "        staging_refugees.RefugeeLikePopulation,\n",
    "        staging_refugees.RefugeeLikePopulationAssistedByUNHCR,\n",
    "        Asylum.CountryKey as AsylumCountryKey,\n",
    "        Origin.CountryKey as OriginCountryKey\n",
    "    FROM staging_refugees \n",
    "    LEFT JOIN CountryDim AS Asylum\n",
    "        ON staging_refugees.AsylumCountry = Asylum.Country\n",
    "    LEFT JOIN CountryDim AS Origin\n",
    "        ON staging_refugees.OriginCountry = Origin.Country\n",
    "    \"\"\")\n",
    "\n",
    "insert_table_queries = [insert_DateDim,\n",
    "                        insert_CountryDim,\n",
    "                        insert_CityDim,\n",
    "                        insert_SourceDim,\n",
    "                        insert_TemperatureFact,\n",
    "                        insert_CountryPopulationFact,\n",
    "                        insert_CityPopulationFact,\n",
    "                        insert_RefugeeFact]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def insert_tables(cur, conn, config):\n",
    "    \"\"\"\n",
    "    Insert data into created fact and dimension tables\n",
    "    \n",
    "    INPUTS:\n",
    "    * cur - the cursor available\n",
    "    * conn - database connection\n",
    "    * config - parameters to Redshift cluster\n",
    "    \"\"\"\n",
    "    \n",
    "    for query in insert_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Call insert table function\n",
    "insert_tables(cur, conn, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
